{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Classification Example with Thetis\n",
    "\n",
    "Thetis can evaluate the AI safety of classifier models.\n",
    "In a first step, we demonstrate how to evaluate and rate your AI model using a basic classification\n",
    "example from [scikit-learn](https://scikit-learn.org/).\n",
    "The instructions below should be easy do adapt to your own use-case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Set Up the Environment\n",
    "\n",
    "In a first step, you need to install Thetis by using pip:\n",
    "\n",
    "```shell\n",
    "$ pip install thetis\n",
    "```\n",
    "\n",
    "Next, you need to obtain a license in order to use Thetis.\n",
    "\n",
    "For the current example, you can use the *demo license* located within the same directory as this notebook.\n",
    "This license only works for our demonstration data set with the exact configuration provided in this notebook.\n",
    "Use the license file [demo_license_classification.dat](https://raw.githubusercontent.com/EFS-OpenSource/Thetis/main/examples/demo_license_classification.dat).\n",
    "\n",
    "A customized *full license*, enabling you to run Thetis with your own data sets and settings, is available our [Subscription Page](https://efs-opensource.github.io/Thetis/subscription.html).\n",
    "\n",
    "Place the license file either in the working directory of your application or at:\n",
    "\n",
    "- Windows: `<User>/AppData/Local/Thetis/license.dat`\n",
    "- Unix: `~/.local/thetis/license.dat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Increase Logging Verbosity\n",
    "\n",
    "For detailed runtime information about Thetis, run the following cell to add a logging handler to the Thetis logger to increase verbosity of the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Configure root logger as catch-all logging config\n",
    "logger = logging.getLogger(\"Thetis\")\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Prepare Example Data and Model\n",
    "\n",
    "To start with our basic classification example, we need to load some data. In this tutorial, we use the\n",
    "[Adult data set](https://www.openml.org/search?type=data&sort=runs&id=179&status=active).\n",
    "This data set demonstrates a prediction task that determines whether a person earns over 50K a year.\n",
    "Let us now load the data set using tools from the scikit-learn library.\n",
    "\n",
    "*Note:* If your machine is behind a proxy server, downloading the example data as shown here may not work.\n",
    "If that is the case for you, check out our [detection example](detection.ipynb) instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "testset_size = 10000\n",
    "\n",
    "# use \"fetch_openml\" by scikit-learn to load \"Adult\" dataset from OpenML\n",
    "dataset, target = fetch_openml(data_id=1590, return_X_y=True, parser=\"auto\")\n",
    "\n",
    "df_train, df_test = dataset.iloc[:-testset_size], dataset.iloc[-testset_size:]\n",
    "target_train, target_test = target.iloc[:-testset_size], target.iloc[-testset_size:]\n",
    "\n",
    "# drop columns with sensitive attributes from classifier input and convert categorical attributes to one-hot\n",
    "df_train_cleared = df_train.drop(columns=[\"education\", \"race\", \"sex\", \"native-country\", \"relationship\", \"marital-status\"])\n",
    "df_test_cleared = df_test.drop(columns=[\"education\", \"race\", \"sex\", \"native-country\", \"relationship\", \"marital-status\"])\n",
    "\n",
    "# convert categorical columns to class codes with integer representation\n",
    "categorical_columns = [\"workclass\", \"occupation\"]\n",
    "df_train_cleared[categorical_columns] = df_train_cleared[categorical_columns].apply(lambda col: pd.Categorical(col).codes)\n",
    "df_test_cleared[categorical_columns] = df_test_cleared[categorical_columns].apply(lambda col: pd.Categorical(col).codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This yields two [Pandas](https://pandas.pydata.org/) data frames with a reduced set of information.\n",
    "\n",
    "In the next step, we train a simple Random Forest classifier on the training data using scikit-learn.\n",
    "Furthermore, we make predictions on the test data using the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# initialize a Random Forest classifier and fit to training data\n",
    "classifier = RandomForestClassifier(verbose=True)\n",
    "classifier.fit(pd.get_dummies(df_train_cleared), target_train)\n",
    "\n",
    "# finally, make predictions on the validation data set\n",
    "confidence = classifier.predict_proba(pd.get_dummies(df_test_cleared))\n",
    "labels = classifier.predict(pd.get_dummies(df_test_cleared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Represent Data as Pandas DataFrames\n",
    "\n",
    "Thetis expects two Pandas data frames to run an evaluation:\n",
    "\n",
    "* Annotations: `pd.DataFrame` with ground-truth information about the data set. The column `target` is required, holding\n",
    "  the ground-truth target information. Furthermore, columns for sensitive attributes are expected that have been\n",
    "  configured for the AI Fairness evaluation.\n",
    "* Predictions: `pd.DataFrame` with the AI predictions for each sample in the data set. The columns `labels` and\n",
    "  `confidence` are required, holding information about the predicted label and the respective prediction\n",
    "  probability (model uncertainty or confidence).\n",
    "\n",
    "Note that the indices of the data frames for annotations and predictions must match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sensitive attributes during safety evaluation\n",
    "annotations = pd.DataFrame({\"target\": target_test, \"race\": df_test[\"race\"], \"sex\": df_test[\"sex\"]})\n",
    "predictions = pd.DataFrame({\"labels\": labels, \"confidence\": confidence[:, 1]}, index=annotations.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Optionally, you can read/write the `pd.DataFrame` instances in CSV format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: store prediction and ground-truth data on disk\n",
    "annotations.to_csv(\"adult_annotations.csv\")\n",
    "predictions.to_csv(\"adult_predictions.csv\")\n",
    "\n",
    "# optional: load prediction and ground-truth data from disk\n",
    "# important: specify \"index_col\" since Thetis matches the predictions/annotations by their indices\n",
    "loaded_annotations = pd.read_csv(\"adult_annotations.csv\", index_col=0)\n",
    "loaded_predictions = pd.read_csv(\"adult_predictions.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Run AI Safety Evaluation with Thetis\n",
    "\n",
    "For all the details of Thetis configuration, see section [Configuration](https://efs-opensource.github.io/Thetis/configuration.html). You can download the [demo configuration file](https://raw.githubusercontent.com/EFS-OpenSource/Thetis/main/examples/demo_config_classification.yaml) for the current example from the this repository or from [here](https://thetishostedfiles.blob.core.windows.net/demofiles/thetis_demo_classification.zip).\n",
    "\n",
    "Thetis returns its findings, the final rating and recommendations for mitigation strategies as a JSON-like dictionary. Below, we capture the dictionary as `result` and can access the different evaluation aspects:\n",
    "\n",
    "* `result[<task>]['rating_score']` for the rating score of the selected task (e.g., 'fairness' or 'uncertainty').\n",
    "* `result[<task>]['recommendations']` for the recommendations to mitigate possible issues of the selected task.\n",
    "* `result[<task>]['rating_enum']` for a categorization of the actual aspect into `'GOOD'`, `'MEDIUM'`,\n",
    "  or `'BAD'` depending on the rating score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thetiscore import thetis\n",
    "\n",
    "\n",
    "result = thetis(\n",
    "   config=\"demo_config_classification.yaml\",\n",
    "   annotations=annotations,\n",
    "   predictions=predictions,\n",
    "   output_dir=\"./output\",\n",
    "   license_file_path=\"demo_license_classification.dat\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
